from abc import ABC, abstractmethod
from typing import Tuple

import numpy as np

from gps.gmm import gauss_fit_joint_prior
from gps.policy import Policy
from gps.sample.sample_list import SampleList


class PolicyPrior(ABC):
    """
    Base class for policy priors used for policy linearization.
    """

    def __init__(self, strength: float = 1e-4):
        """

        :param strength: The strength of the prior.
        """
        self.__strength = strength

    @abstractmethod
    def update(self, samples: SampleList, policy: Policy, replace_samples: bool = False) -> "PolicyPrior":
        """
        Updates the controller prior.
        :param samples:         Samples to update prior with.
        :param policy:          Policy to compute prior for.
        :param replace_samples: True, if previously recorded samples
        :return:
        """
        pass

    @abstractmethod
    def eval(self, states: np.ndarray, actions: np.ndarray) -> Tuple[np.ndarray, np.ndarray, float, float]:
        """
        Evaluate the controller prior for the given states and actions.
        :param states:  N x STATE_DIMS array of states
        :param actions: N x ACTION_DIMS array of actions
        :return:
        """
        pass

    def fit(self, states: np.ndarray, action_means: np.ndarray, action_covariances: np.ndarray) \
            -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        Fit controller linearization.
        :param states:              (N x NUM_TIMESTEPS x STATE_DIMS) array of states
        :param action_means:        (N x NUM_TIMESTEPS x ACTION_DIMS) array of actions (generated by the policy)
        :param action_covariances:  (N x NUM_TIMESTEPS x ACTION_DIMS x ACTION_DIMS) array of action covariances
        :return:
        """
        n, ts, dx = states.shape
        du = action_means.shape[2]
        assert n > 1, "Cannot fit dynamics on 1 sample"

        # Collapse controller covariances. (This is only correct because
        # the controller doesn't depend on state).
        action_covariances = np.mean(action_covariances, axis=0)

        # Allocate.
        pol_K = np.zeros([ts, du, dx])
        pol_k = np.zeros([ts, du])
        pol_S = np.zeros([ts, du, du])

        # Fit controller linearization with least squares regression.
        dwts = (1.0 / n) * np.ones(n)
        for t in range(ts):
            Ts = states[:, t, :]
            Ps = action_means[:, t, :]
            Ys = np.concatenate([Ts, Ps], axis=1)
            # Obtain Normal-inverse-Wishart prior.
            mu0, Phi, mm, n0 = self.eval(Ts, Ps)
            sig_reg = np.zeros((dx + du, dx + du))
            # Slightly regularize on first timestep.
            if t == 0:
                sig_reg[:dx, :dx] = 1e-8
            pol_K[t, :, :], pol_k[t, :], pol_S[t, :, :] = gauss_fit_joint_prior(Ys, mu0, Phi, mm, n0, dwts, dx, du,
                                                                                sig_reg)
        pol_S += action_covariances
        return pol_K, pol_k, pol_S

    @property
    def strength(self) -> float:
        return self.__strength
